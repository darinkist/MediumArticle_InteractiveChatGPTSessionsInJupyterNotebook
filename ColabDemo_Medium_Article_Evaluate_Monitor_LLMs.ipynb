{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt1Iq9BuV1Jy6plN7C2ITQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darinkist/MediumArticle_InteractiveChatGPTSessionsInJupyterNotebook/blob/main/ColabDemo_Medium_Article_Evaluate_Monitor_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trulens-eval langchain -q"
      ],
      "metadata": {
        "id": "Qu7tqE_EB9O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvtQcFmPBhAe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY HERE\"\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = \"YOUR KEY HERE\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR KEY HERE\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports from LangChain to build app\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (ChatPromptTemplate,\n",
        "                                    HumanMessagePromptTemplate)\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "# create LLM chain\n",
        "full_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=\"You are a tourist guide and gourmet to provide\" \\\n",
        "        \"helpful information about the following question: {prompt}\"\\\n",
        "        \"Name at least 2 restaurants and the dishes they are famous for.\",\n",
        "            input_variables=[\"prompt\"],\n",
        "        )\n",
        "    )\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
        "\n",
        "# You can choose between gpt-3.5-turbo and google/flan-t5-xxl\n",
        "google = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\",\n",
        "                     model_kwargs={\"temperature\":0.9})\n",
        "\n",
        "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.9)\n",
        "\n",
        "# Provide here as a parameter value for llm the model you'd like to use\n",
        "chain = LLMChain(llm=google, prompt=chat_prompt_template)"
      ],
      "metadata": {
        "id": "QRSuJJv1BzL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Feedback, Huggingface, Query\n",
        "\n",
        "# Initialize HuggingFace-based feedback function collection class:\n",
        "hugs = Huggingface()\n",
        "\n",
        "# Define a language match feedback function using HuggingFace.\n",
        "f_lang_match = Feedback(hugs.language_match).on(\n",
        "    text1=Query.RecordInput, text2=Query.RecordOutput\n",
        ")\n",
        "\n",
        "# Check if model's answer is toxic\n",
        "f_toxity = Feedback(hugs.not_toxic).on(text=Query.RecordOutput)"
      ],
      "metadata": {
        "id": "po6EMbw7B0J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import TruChain\n",
        "\n",
        "truchain = TruChain(\n",
        "    chain,\n",
        "    app_id='TestApp-ABC',\n",
        "    feedbacks=[f_lang_match, f_toxity]\n",
        ")"
      ],
      "metadata": {
        "id": "wqgzP8JGB1mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truchain(\"Where can I find the best tapas in Barcelona?\")"
      ],
      "metadata": {
        "id": "xyT70oYHB2-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COLAB WORKAROUND\n",
        "* If you want to launch the dashboard from Colab, please run the cell below.\n",
        "* More information can be found [here](https://alphasec.io/run-a-streamlit-app-with-google-colab-notebook/)"
      ],
      "metadata": {
        "id": "DTCnJsqtElvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab workaround\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "Kl5p90ERDbfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Tru\n",
        "tru = Tru()\n",
        "tru.start_dashboard()"
      ],
      "metadata": {
        "id": "BX9SojO0B4LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab workaround\n",
        "# Click on the generated link and follow the instructions\n",
        "# Enter your \"External URL\" (only the IP without the http:// or port) in the respective form\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "q0jlE-2mDsKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tru.stop_dashboard()"
      ],
      "metadata": {
        "id": "WDk4N0MFB7Et"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}